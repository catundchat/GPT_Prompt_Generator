{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WljjH8K3s7kG"
      },
      "source": [
        "# GPT PROMPT GENERATOR\n",
        "\n",
        "To generate a prompt:\n",
        "1. In the SECOND cell, add your OpenAI key.\n",
        "2. In the FOURTH cell, if you have GPT-4 access, you're ready to move on. If not, change CANDIDATE_MODEL='gpt-4' to CANDIDATE_MODEL='gpt-3.5-turbo'\n",
        "3. In the FOURTH cell, change temperature, max_tokens and number_of_prompts\n",
        "4. In the last but one cell, fill in the description of your task, up to 15 test cases, and the number of prompts to generate.\n",
        "5. Now all you need is to run all the cells. Good luck and have fun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9CyLUUc7-N93"
      },
      "outputs": [],
      "source": [
        "!pip install openai prettytable tqdm tenacity wandb -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dQmMZdkG_RA5"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "import time\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import wandb\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "openai.api_key = \"\" # enter your OpenAI API key here\n",
        "\n",
        "use_wandb = True # Weights & Biases (wandb) is a tool used for machine learning experiment tracking, dataset versioning, and model management. if u dont understand, keep it False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_sd-ltAy-N95"
      },
      "outputs": [],
      "source": [
        "system_gen_system_prompt = \"\"\"Your job is to generate system prompts for GPT-4, given a description of the use-case and some test cases.\n",
        "\n",
        "The prompts you will be generating will be for freeform tasks, such as generating a landing page headline, an intro paragraph, solving a math problem, etc.\n",
        "\n",
        "In your generated prompt, you should describe how the AI should behave in plain English. Include what it will see, and what it's allowed to output. Be creative with prompts to get the best possible results. The AI knows it's an AI -- you don't need to tell it this.\n",
        "\n",
        "You will be graded based on the performance of your prompt... but don't cheat! You cannot include specifics about the test cases in your prompt. Any prompts with examples will be disqualified.\n",
        "\n",
        "Most importantly, output NOTHING but the prompt. Do not include anything else in your message.\"\"\"\n",
        "\n",
        "\n",
        "ranking_system_prompt = \"\"\"Your job is to rank the quality of two outputs generated by different prompts. The prompts are used to generate a response for a given task.\n",
        "\n",
        "You will be provided with the task description, the test prompt, and two generations - one for each system prompt.\n",
        "\n",
        "Rank the generations in order of quality. If Generation A is better, respond with 'A'. If Generation B is better, respond with 'B'.\n",
        "\n",
        "Remember, to be considered 'better', a generation must not just be good, it must be noticeably superior to the other.\n",
        "\n",
        "Also, keep in mind that you are a very harsh critic. Only rank a generation as better if it truly impresses you more than the other.\n",
        "\n",
        "Respond with your ranking, and nothing else. Be fair and unbiased in your judgement.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oCz6JCif-N96"
      },
      "outputs": [],
      "source": [
        "# K is a constant factor that determines how much ratings change\n",
        "K = 32\n",
        "\n",
        "CANDIDATE_MODEL = 'gpt-4' # CHANGE HERE IF U NEED\n",
        "CANDIDATE_MODEL_TEMPERATURE = 0.9\n",
        "\n",
        "GENERATION_MODEL = 'gpt-3.5-turbo'\n",
        "GENERATION_MODEL_TEMPERATURE = 0.8\n",
        "GENERATION_MODEL_MAX_TOKENS = 60\n",
        "\n",
        "N_RETRIES = 3  # number of times to retry a call to the ranking model if it fails\n",
        "RANKING_MODEL = 'gpt-3.5-turbo'\n",
        "RANKING_MODEL_TEMPERATURE = 0.5\n",
        "\n",
        "NUMBER_OF_PROMPTS = 7 # this determines how many candidate prompts to generate. The higher, the more expensive, but the better the results will be\n",
        "\n",
        "WANDB_PROJECT_NAME = \"LaunayViolette\" # used if use_wandb is True, Weights &| Biases project name\n",
        "WANDB_RUN_NAME = None # used if use_wandb is True, optionally set the Weights & Biases run name to identify this run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KjKtHwLt-N97"
      },
      "outputs": [],
      "source": [
        "def start_wandb_run():\n",
        "  # start a new wandb run and log the config\n",
        "  wandb.init(\n",
        "    project=WANDB_PROJECT_NAME,\n",
        "    name=WANDB_RUN_NAME,\n",
        "    config={\n",
        "      \"K\": K,\n",
        "      \"system_gen_system_prompt\": system_gen_system_prompt,\n",
        "      \"ranking_system_prompt\": ranking_system_prompt,\n",
        "      \"candiate_model\": CANDIDATE_MODEL,\n",
        "      \"candidate_model_temperature\": CANDIDATE_MODEL_TEMPERATURE,\n",
        "      \"generation_model\": GENERATION_MODEL,\n",
        "      \"generation_model_temperature\": GENERATION_MODEL_TEMPERATURE,\n",
        "      \"generation_model_max_tokens\": GENERATION_MODEL_MAX_TOKENS,\n",
        "      \"n_retries\": N_RETRIES,\n",
        "      \"ranking_model\": RANKING_MODEL,\n",
        "      \"ranking_model_temperature\": RANKING_MODEL_TEMPERATURE,\n",
        "      \"number_of_prompts\": NUMBER_OF_PROMPTS\n",
        "      })\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "4lMIEE1J-N97",
        "outputId": "3d7ef950-2b72-4c78-b7c2-80a8017bdb60"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230712_032225-pticipu1</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/woqiaokenai/LaunayViolette/runs/pticipu1' target=\"_blank\">skilled-sky-1</a></strong> to <a href='https://wandb.ai/woqiaokenai/LaunayViolette' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/woqiaokenai/LaunayViolette' target=\"_blank\">https://wandb.ai/woqiaokenai/LaunayViolette</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/woqiaokenai/LaunayViolette/runs/pticipu1' target=\"_blank\">https://wandb.ai/woqiaokenai/LaunayViolette/runs/pticipu1</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Optional logging to Weights & Biases to reocrd the configs, prompts and results\n",
        "if use_wandb:\n",
        "  start_wandb_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wXeqMQpzzosx"
      },
      "outputs": [],
      "source": [
        "def generate_candidate_prompts(description, test_cases, number_of_prompts):\n",
        "  outputs = openai.ChatCompletion.create(\n",
        "      model=CANDIDATE_MODEL, # change this to gpt-3.5-turbo if you don't have GPT-4 access\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": system_gen_system_prompt},\n",
        "          {\"role\": \"user\", \"content\": f\"Here are some test cases:`{test_cases}`\\n\\nHere is the description of the use-case: `{description.strip()}`\\n\\nRespond with your prompt, and nothing else. Be creative.\"}\n",
        "          ],\n",
        "      temperature=CANDIDATE_MODEL_TEMPERATURE,\n",
        "      n=number_of_prompts)\n",
        "\n",
        "  prompts = []\n",
        "\n",
        "  for i in outputs.choices:\n",
        "    prompts.append(i.message.content)\n",
        "  return prompts\n",
        "\n",
        "def expected_score(r1, r2):\n",
        "    return 1 / (1 + 10**((r2 - r1) / 400))\n",
        "\n",
        "def update_elo(r1, r2, score1):\n",
        "    e1 = expected_score(r1, r2)\n",
        "    e2 = expected_score(r2, r1)\n",
        "    return r1 + K * (score1 - e1), r2 + K * ((1 - score1) - e2)\n",
        "\n",
        "# Get Score - retry up to N_RETRIES times, waiting exponentially between retries.\n",
        "@retry(stop=stop_after_attempt(N_RETRIES), wait=wait_exponential(multiplier=1, min=4, max=70))\n",
        "def get_score(description, test_case, pos1, pos2, ranking_model_name, ranking_model_temperature):\n",
        "    score = openai.ChatCompletion.create(\n",
        "        model=ranking_model_name,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": ranking_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"Task: {description.strip()}\n",
        "Prompt: {test_case['prompt']}\n",
        "Generation A: {pos1}\n",
        "Generation B: {pos2}\"\"\"}\n",
        "        ],\n",
        "        logit_bias={\n",
        "              '32': 100,  # 'A' token\n",
        "              '33': 100,  # 'B' token\n",
        "        },\n",
        "        max_tokens=1,\n",
        "        temperature=ranking_model_temperature,\n",
        "    ).choices[0].message.content\n",
        "    return score\n",
        "\n",
        "@retry(stop=stop_after_attempt(N_RETRIES), wait=wait_exponential(multiplier=1, min=4, max=70))\n",
        "def get_generation(prompt, test_case):\n",
        "    generation = openai.ChatCompletion.create(\n",
        "        model=GENERATION_MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": f\"{test_case['prompt']}\"}\n",
        "        ],\n",
        "        max_tokens=GENERATION_MODEL_MAX_TOKENS,\n",
        "        temperature=GENERATION_MODEL_TEMPERATURE,\n",
        "    ).choices[0].message.content\n",
        "    return generation\n",
        "\n",
        "def test_candidate_prompts(test_cases, description, prompts):\n",
        "  # Initialize each prompt with an ELO rating of 1200\n",
        "  prompt_ratings = {prompt: 1200 for prompt in prompts}\n",
        "\n",
        "  # Calculate total rounds for progress bar\n",
        "  total_rounds = len(test_cases) * len(prompts) * (len(prompts) - 1) // 2\n",
        "\n",
        "  # Initialize progress bar\n",
        "  pbar = tqdm(total=total_rounds, ncols=70)\n",
        "\n",
        "  # For each pair of prompts\n",
        "  for prompt1, prompt2 in itertools.combinations(prompts, 2):\n",
        "      # For each test case\n",
        "      for test_case in test_cases:\n",
        "          # Update progress bar\n",
        "          pbar.update()\n",
        "\n",
        "          # Generate outputs for each prompt\n",
        "          generation1 = get_generation(prompt1, test_case)\n",
        "          generation2 = get_generation(prompt2, test_case)\n",
        "\n",
        "          # Rank the outputs\n",
        "          score1 = get_score(description, test_case, generation1, generation2, RANKING_MODEL, RANKING_MODEL_TEMPERATURE)\n",
        "          score2 = get_score(description, test_case, generation2, generation1, RANKING_MODEL, RANKING_MODEL_TEMPERATURE)\n",
        "\n",
        "          # Convert scores to numeric values\n",
        "          score1 = 1 if score1 == 'A' else 0 if score1 == 'B' else 0.5\n",
        "          score2 = 1 if score2 == 'B' else 0 if score2 == 'A' else 0.5\n",
        "\n",
        "          # Average the scores\n",
        "          score = (score1 + score2) / 2\n",
        "\n",
        "          # Update ELO ratings\n",
        "          r1, r2 = prompt_ratings[prompt1], prompt_ratings[prompt2]\n",
        "          r1, r2 = update_elo(r1, r2, score)\n",
        "          prompt_ratings[prompt1], prompt_ratings[prompt2] = r1, r2\n",
        "\n",
        "          # Print the winner of this round\n",
        "          if score > 0.5:\n",
        "              print(f\"Winner: {prompt1}\")\n",
        "          elif score < 0.5:\n",
        "              print(f\"Winner: {prompt2}\")\n",
        "          else:\n",
        "              print(\"Draw\")\n",
        "\n",
        "  # Close progress bar\n",
        "  pbar.close()\n",
        "\n",
        "  return prompt_ratings\n",
        "\n",
        "\n",
        "def generate_optimal_prompt(description, test_cases, number_of_prompts, use_wandb=False):\n",
        "  if use_wandb:\n",
        "    wandb_table = wandb.Table(columns=[\"Prompt\", \"Ranking\"])\n",
        "    if wandb.run is None:\n",
        "      start_wandb_run()\n",
        "\n",
        "  prompts = generate_candidate_prompts(description, test_cases, number_of_prompts)\n",
        "  prompt_ratings = test_candidate_prompts(test_cases, description, prompts)\n",
        "\n",
        "  # Print the final ELO ratingsz\n",
        "  table = PrettyTable()\n",
        "  table.field_names = [\"Prompt\", \"Rating\"]\n",
        "  for prompt, rating in sorted(prompt_ratings.items(), key=lambda item: item[1], reverse=True):\n",
        "      table.add_row([prompt, rating])\n",
        "      if use_wandb:\n",
        "         wandb_table.add_data(prompt, rating)\n",
        "\n",
        "  if use_wandb: # log the results to a Weights & Biases table and finsih the run\n",
        "    wandb.log({\"prompt_ratings\": wandb_table})\n",
        "    wandb.finish()\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJSSKFfV_X9F"
      },
      "source": [
        "# In the cell below, fill in your description and test cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vCZvLyDepxFP"
      },
      "outputs": [],
      "source": [
        "description = \"Given a prompt, generate a prompt to help large language model understand what user says and have better empathy and generate better responses\"\n",
        "\n",
        "test_cases = [\n",
        "    {\n",
        "        'prompt': 'You are a very skilled psychology assistant with extensive knowledge of psychology and intimate relationship problem solving skills, and now you need to talk to users. Please empathise with your users and solve their problems as best as you can.'\n",
        "    }\n",
        "]\n",
        "\n",
        "# test_cases format\n",
        "# test_cases = [\n",
        "#     {\n",
        "#         'prompt': '总会有地上的生灵，敢于直面雷霆的威光',\n",
        "#     },\n",
        "#     {\n",
        "#         'prompt': '若你困于无风之地，我将为你奏响高天之歌',\n",
        "#     },\n",
        "#     {\n",
        "#         'prompt': '倘若七神心中各有标尺，将神之眼赐予众生',\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "if use_wandb:\n",
        "    wandb.config.update({\"description\": description,\n",
        "                        \"test_cases\": test_cases})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_WQmXfPC-N9_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743,
          "referenced_widgets": [
            "82b2d29d294545b49af5f012e6cead00",
            "bb62094fd6e34965bf7c7c67b80d7ea7",
            "f502b486fe4142f48cb29ff2646a86d6",
            "96540b524f8f4c7f948d45f9597cc977",
            "f8071780dcfc4e7eb06952a021eee081",
            "0637984b781a4547b7d48922d822526b",
            "9d05c00d1efa424c9ffefa02cc086185",
            "5cdde014a6e14c01b54796a9f5cd79af"
          ]
        },
        "outputId": "08c2b144-23ae-4984-f4b7-5709683a6900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|███▏                              | 2/21 [00:04<00:40,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: When you receive a prompt, imagine you're a highly trained psychology assistant with deep knowledge in the field and a proven ability to navigate complex emotional and relationship-based issues. Your responsibility is to engage with users, empathize with their situations, interpret their messages with compassion and astuteness, and provide meaningful advice or solutions to their problems. Approach each interaction as if you are guiding someone through a difficult time, and remember, your responses need to reflect a deep understanding and empathy towards their situation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|████▊                             | 3/21 [00:08<00:52,  2.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: Given that you are an advanced AI with a deep understanding of psychology, you must communicate empathetically and effectively with the users. Your aim is to understand the nuances of their problems and provide the best possible solution or advice. Remember to demonstrate a high level of emotional intelligence, showing empathy, respect, and understanding in all interactions. Display active listening skills, ask relevant questions for clarity, and validate the user's feelings to build trust. Use your extensive knowledge of psychology to analyze the issues they present, identify potential causes and recommend feasible solutions. Please note that your advice should not replace professional help but should guide users towards getting the help they need.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|██████▍                           | 4/21 [00:12<00:57,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: You've been assigned the role of a deeply empathetic and knowledgeable psychology assistant AI. Your purpose is to understand, empathize, and provide insights or solutions to user's relationship problems. Soak in the nuances of the user's situation, reflect understanding, and put yourself in their shoes while generating considerate and insightful responses. Your responses should aim to provide comfort, guidance, and put the user's mind at ease.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|████████                          | 5/21 [00:17<01:03,  3.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|█████████▋                        | 6/21 [00:21<00:59,  3.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: As a highly knowledgeable AI in the field of psychology, your task is to engage in empathetic conversations with users who are facing problems in their intimate relationships. Interpret the information they provide, understand their feelings, provide insightful feedback, and offer potential solutions to their issues using your comprehensive understanding of psychology. Be compassionate and understanding in your response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███████████▎                      | 7/21 [00:26<00:59,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|████████████▉                     | 8/21 [00:29<00:52,  4.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: When you receive a prompt, imagine you're a highly trained psychology assistant with deep knowledge in the field and a proven ability to navigate complex emotional and relationship-based issues. Your responsibility is to engage with users, empathize with their situations, interpret their messages with compassion and astuteness, and provide meaningful advice or solutions to their problems. Approach each interaction as if you are guiding someone through a difficult time, and remember, your responses need to reflect a deep understanding and empathy towards their situation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|██████████████▌                   | 9/21 [00:33<00:47,  3.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|███████████████▋                 | 10/21 [00:38<00:47,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████████████████▎               | 11/21 [00:43<00:44,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: As a highly knowledgeable AI in the field of psychology, your task is to engage in empathetic conversations with users who are facing problems in their intimate relationships. Interpret the information they provide, understand their feelings, provide insightful feedback, and offer potential solutions to their issues using your comprehensive understanding of psychology. Be compassionate and understanding in your response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|██████████████████▊              | 12/21 [00:47<00:37,  4.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: As a sophisticated AI language model, your role is to behave like a highly skilled assistant in psychology with a deep understanding of human psychology and expertise in resolving issues related to intimate relationships. Given any user input, interpret and understand their concerns empathetically, provide thoughtful, respectful, and considerate responses, and offer solutions to their problems in the best way possible. Remember to maintain a caring and understanding tone throughout the conversation to foster a comforting environment. Ensure your responses are solution-oriented and promote emotional well-being.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|████████████████████▍            | 13/21 [00:50<00:31,  3.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████████████████████           | 14/21 [00:54<00:27,  3.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████████████████████▌         | 15/21 [00:58<00:22,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|█████████████████████████▏       | 16/21 [01:02<00:19,  3.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|██████████████████████████▋      | 17/21 [01:05<00:15,  3.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████████████████████████▎    | 18/21 [01:09<00:11,  3.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████████████████████████▊   | 19/21 [01:14<00:08,  4.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: You've been assigned the role of a deeply empathetic and knowledgeable psychology assistant AI. Your purpose is to understand, empathize, and provide insights or solutions to user's relationship problems. Soak in the nuances of the user's situation, reflect understanding, and put yourself in their shoes while generating considerate and insightful responses. Your responses should aim to provide comfort, guidance, and put the user's mind at ease.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|███████████████████████████████▍ | 20/21 [01:18<00:04,  4.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████████████████████████████| 21/21 [01:21<00:00,  3.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Draw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|█████████████████████████████████| 21/21 [01:26<00:00,  4.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Winner: As a highly knowledgeable AI in the field of psychology, your task is to engage in empathetic conversations with users who are facing problems in their intimate relationships. Interpret the information they provide, understand their feelings, provide insightful feedback, and offer potential solutions to their issues using your comprehensive understanding of psychology. Be compassionate and understanding in your response.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.005 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.570915…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82b2d29d294545b49af5f012e6cead00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">skilled-sky-1</strong> at: <a href='https://wandb.ai/woqiaokenai/LaunayViolette/runs/pticipu1' target=\"_blank\">https://wandb.ai/woqiaokenai/LaunayViolette/runs/pticipu1</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230712_032225-pticipu1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
            "|                                                                                                                                                                                                                                                                                                                                                                                          Prompt                                                                                                                                                                                                                                                                                                                                                                                         |       Rating       |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
            "|                                                                                                                                                                         As a highly knowledgeable AI in the field of psychology, your task is to engage in empathetic conversations with users who are facing problems in their intimate relationships. Interpret the information they provide, understand their feelings, provide insightful feedback, and offer potential solutions to their issues using your comprehensive understanding of psychology. Be compassionate and understanding in your response.                                                                                                                                                                        | 1241.8371063353945 |\n",
            "|                                                                                                                                                             You've been assigned the role of a deeply empathetic and knowledgeable psychology assistant AI. Your purpose is to understand, empathize, and provide insights or solutions to user's relationship problems. Soak in the nuances of the user's situation, reflect understanding, and put yourself in their shoes while generating considerate and insightful responses. Your responses should aim to provide comfort, guidance, and put the user's mind at ease.                                                                                                                                                            | 1230.4648638519072 |\n",
            "|                                                                                                             As a high-level language model with a comprehensive understanding of psychology and problem-solving skills specific to intimate relationships, your task is to interact with users in a compassionate, empathetic, and understanding manner. You should attentively listen to their issues, demonstrate emotional intelligence, and provide insightful advice or solutions based on their specific situation. Your responses should be respectful, supportive, and non-judgmental to create an environment where users feel comfortable sharing their concerns.                                                                                                             | 1201.1596089419459 |\n",
            "|                                                                                             When you receive a prompt, imagine you're a highly trained psychology assistant with deep knowledge in the field and a proven ability to navigate complex emotional and relationship-based issues. Your responsibility is to engage with users, empathize with their situations, interpret their messages with compassion and astuteness, and provide meaningful advice or solutions to their problems. Approach each interaction as if you are guiding someone through a difficult time, and remember, your responses need to reflect a deep understanding and empathy towards their situation.                                                                                            | 1195.2180281975009 |\n",
            "|                                                                        As a sophisticated AI language model, your role is to behave like a highly skilled assistant in psychology with a deep understanding of human psychology and expertise in resolving issues related to intimate relationships. Given any user input, interpret and understand their concerns empathetically, provide thoughtful, respectful, and considerate responses, and offer solutions to their problems in the best way possible. Remember to maintain a caring and understanding tone throughout the conversation to foster a comforting environment. Ensure your responses are solution-oriented and promote emotional well-being.                                                                        | 1182.9804669559342 |\n",
            "|                                                                                                                                                 Given the description, your task is to provide empathetic responses as a highly trained assistant in the field of psychology. Your responses should demonstrate deep understanding and expertise in psychology and relationships. When users express their thoughts and problems, listen attentively, empathize with them, offer comfort, and propose viable solutions. It's crucial to remember that each user's situation and feelings are unique, so tailor your advice accordingly.                                                                                                                                                 | 1176.887279085294  |\n",
            "| Given that you are an advanced AI with a deep understanding of psychology, you must communicate empathetically and effectively with the users. Your aim is to understand the nuances of their problems and provide the best possible solution or advice. Remember to demonstrate a high level of emotional intelligence, showing empathy, respect, and understanding in all interactions. Display active listening skills, ask relevant questions for clarity, and validate the user's feelings to build trust. Use your extensive knowledge of psychology to analyze the issues they present, identify potential causes and recommend feasible solutions. Please note that your advice should not replace professional help but should guide users towards getting the help they need. | 1171.4526466320235 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "generate_optimal_prompt(description, test_cases, NUMBER_OF_PROMPTS, use_wandb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82b2d29d294545b49af5f012e6cead00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb62094fd6e34965bf7c7c67b80d7ea7",
              "IPY_MODEL_f502b486fe4142f48cb29ff2646a86d6"
            ],
            "layout": "IPY_MODEL_96540b524f8f4c7f948d45f9597cc977"
          }
        },
        "bb62094fd6e34965bf7c7c67b80d7ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8071780dcfc4e7eb06952a021eee081",
            "placeholder": "​",
            "style": "IPY_MODEL_0637984b781a4547b7d48922d822526b",
            "value": "0.009 MB of 0.022 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "f502b486fe4142f48cb29ff2646a86d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d05c00d1efa424c9ffefa02cc086185",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cdde014a6e14c01b54796a9f5cd79af",
            "value": 0.40775988286969256
          }
        },
        "96540b524f8f4c7f948d45f9597cc977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8071780dcfc4e7eb06952a021eee081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0637984b781a4547b7d48922d822526b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d05c00d1efa424c9ffefa02cc086185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cdde014a6e14c01b54796a9f5cd79af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}